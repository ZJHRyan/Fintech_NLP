{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-8-c2ad93d91e10>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mgensim\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mcorpora\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mgensim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodels\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mLdaModel\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mgensim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcorpora\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mDictionary\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpyLDAvis\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgensim_models\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mre\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "import pyLDAvis.gensim_models\n",
    "import re\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "import paddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paddle.enable_static()\n",
    "jieba.enable_paddle()\n",
    "jieba.set_dictionary('../resource/dict.txt.big')\n",
    "jieba.analyse.set_stop_words(\"../resource/stopwords.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [line.strip() for line in open('../resource/stopwords.txt', 'r', encoding='utf-8').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg_sentence(sentence):\n",
    "    sentence = re.sub(u'[0-9\\.]+', u'', sentence)\n",
    "    sentence_seged = jieba.cut(sentence.strip(),use_paddle=True)\n",
    "    outstr = ''\n",
    "    for word in sentence_seged:\n",
    "        if word not in stopwords and word.__len__()>1:\n",
    "            if word != '\\t':\n",
    "                outstr += word\n",
    "                outstr += \" \"\n",
    "    return outstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = open('../1.txt', 'r', encoding='utf-8')\n",
    "\n",
    "outputs = open('output.txt', 'w',encoding='utf-8')\n",
    "for line in inputs:\n",
    "    punc = \"[【】╮╯▽╰╭★→「」！，❤。～《》：()／（）”“；：、！：，。？、~@#￥%……&*]+\"\n",
    "    line = re.sub(punc, \"\", line)\n",
    "    line_seg = seg_sentence(line)  # 这里的返回值是字符串\n",
    "    outputs.write(line_seg + '\\n')\n",
    "outputs.close()\n",
    "inputs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "\n",
    "fp = open('output.txt','r',encoding='utf8')\n",
    "for line in fp:\n",
    "    if line != '':\n",
    "        line = line.split()\n",
    "        train.append([w for w in line])\n",
    "\n",
    "dictionary = corpora.Dictionary(train)\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in train]\n",
    "\n",
    "lda = LdaModel(corpus=corpus, id2word=dictionary, num_topics=20, passes=60)\n",
    "# num_topics：主题数目\n",
    "# passes：训练伦次\n",
    "# num_words：每个主题下输出的term的数目\n",
    "\n",
    "for topic in lda.print_topics(num_words = 20):\n",
    "    termNumber = topic[0]\n",
    "    print(topic[0], ':', sep='')\n",
    "    listOfTerms = topic[1].split('+')\n",
    "    for term in listOfTerms:\n",
    "        listItems = term.split('*')\n",
    "        print('  ', listItems[1], '(', listItems[0], ')', sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=pyLDAvis.gensim_models.prepare(lda, corpus, dictionary)\n",
    "pyLDAvis.show(d)\t\t#展示在浏览器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(d,'1.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d063fc264da33a9568bce20a9e53c95631362be94737b6a5312f6f5f347591c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}